<div align="center">
<h1>Order Matters: Learning Element Ordering for <br> Graphic Design Generation (TOG 2025)</h1>

[Bo Yang](https://borisyang326.github.io/), [Ying Caoâ€ ](https://www.ying-cao.com/)

<sup>â€ </sup>Corresponding Author

ShanghaiTech University

<a href='https://dl.acm.org/doi/10.1145/3730858'><img src='https://img.shields.io/badge/Paper-PDF-red'></a>
<a href='https://borisyang326.github.io/ordermatters.html'><img src='https://img.shields.io/badge/Project-Page-green'></a>
<a href='https://github.com/borisyang326/OrderGOL'><img src='https://img.shields.io/badge/Github-Code-bb8a2e?logo=github'></a>
[![GitHub](https://img.shields.io/github/stars/borisyang326/OrderGOL?style=social)](https://github.com/borisyang326/OrderGOL)

</div>

<p align="center">
  <img src="assets/teaser_v5.jpg" alt="Teaser showing comparison of graphic designs generated with different ordering strategies">
</p>

## ğŸ·ï¸ Change Log 

- [2025/08/05] ğŸ”¥ We release the source code and checkpoints.
- [2025/04/30] ğŸ”¥ We release the <a href='https://borisyang326.github.io/ordermatters.html'>project page</a>.
- [2025/04/27] ğŸ“„ Paper accepted to ACM Transactions on Graphics (SIGGRAPH 2025).

## ğŸ”† Method Overview

<p align="center">
  <img src="assets/full_pipe-v4.png" alt="GOL Framework Pipeline">
</p>

We propose a **G**enerative **O**rder **L**earner (GOL) that learns optimal element ordering strategies for graphic design generation. Our approach consists of:

- **Design Generator**: A Transformer-based autoregressive model that generates design sequences
- **Ordering Network**: A neural network that learns content-adaptive element ordering
- **Joint Training**: Both networks are trained simultaneously for mutual improvement

The key insight is that the order in which design elements are generated significantly impacts the quality of the final design. Our neural order outperforms random and raster ordering strategies.

## âš™ï¸ Setup

### Environment Setup
```bash
conda env create -f requirements.yml
conda activate ordergol   
pip install torch==2.1.1 torchvision==0.16.1 torchaudio==2.1.1 --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt
```

### Dataset Setup
1. **Download the Crello Dataset**
   
   Download [crello.zip](https://drive.google.com/file/d/1YZ2gjCC0QMPdr18oYEe8mv_w5RO_eYDX/view?usp=sharing) from the provided link and place it in your project directory.

2. **Extract Dataset**
   ```bash
   unzip crello.zip
   mv crello data/
   ```
   
   The dataset should be organized as:
   ```
   data/
   â””â”€â”€ crello/
       â”œâ”€â”€ cache/          # Preprocessed .pt files (auto-generated)
       â”œâ”€â”€ weights/        # Clustering information for preprocessing
       â””â”€â”€ ...            # Other dataset files
   ```

**Note**: The `CrelloDataset` class will prioritize loading preprocessed `.pt` files from `data/cache/`. If these files are not found, it will automatically preprocess the data based on pre-computed clustering information in `data/weights/`.

## ğŸš€ Training

For detailed training instructions, see [TRAIN.md](TRAIN.md).

## ğŸ¯ Evaluation

For detailed evaluation instructions, see [EVAL.md](EVAL.md).


## ğŸ“ Project Structure

```
OrderGOL/
â”œâ”€â”€ configs/               # YAML Configuration files
â”œâ”€â”€ data/                  # Dataset directory
â”œâ”€â”€ ckpt/                  # Model checkpoints
â”œâ”€â”€ src/                   # Source code
â”‚   â”œâ”€â”€ model/             # Design Generator implementations
â”‚   â”‚   â”œâ”€â”€ design_transformer.py
â”‚   â”‚   â”œâ”€â”€ layout_transformer.py
â”‚   â”‚   â”œâ”€â”€ codebook.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ scorer.py          # Ordering Network (main component)
â”‚   â”œâ”€â”€ sort.py            # Neural sorting algorithms
â”‚   â”œâ”€â”€ dataset/           # Data load, preprocess and rendering
â”‚   â”‚   â”œâ”€â”€ crello_dataset.py
â”‚   â”‚   â”œâ”€â”€ helpers/
â”‚   â”‚   â””â”€â”€ ...  
â”‚   â”œâ”€â”€ fid/               # FID computation (seq/visual embedding space)
â”‚   â”‚   â”œâ”€â”€ seq/           # Sequential embeddings
â”‚   â”‚   â””â”€â”€ visual/        # Visual embeddings
â”‚   â”œâ”€â”€ configs.py         # Experiment configurations (non-YAML args)
â”‚   â”œâ”€â”€ trainer.py         # Training pipeline
â”‚   â”œâ”€â”€ sampling.py        # Sampling strategies
â”‚   â”œâ”€â”€ metric.py          # Evaluation metrics
â”‚   â”œâ”€â”€ preprocess.py      # Data preprocessing utilities
â”‚   â”œâ”€â”€ saliency/          # Saliency-related utilities
â”‚   â””â”€â”€ utils.py           # Helper functions
â”œâ”€â”€ train.sh               # Training script
â”œâ”€â”€ eval.sh                # Evaluation script  
â”œâ”€â”€ main.py                # Entry point
â”œâ”€â”€ assets/                # Repo figures
â”œâ”€â”€ requirements.txt/yml   # Python dependencies
â””â”€â”€ README.md              # This file
```

## â¤ï¸ Acknowledgments

This project is built upon several excellent open-source projects:
- [LayoutDM](https://github.com/CyberAgentAILab/layout-dm): main hydra-based training pipe, diffusion-based design generator.
- [LayoutTransformer](https://github.com/kampta/DeepLayout): dataset utilities, auto-regressive design generator.

We thank the authors of these projects for their contributions to the open-source community.

## ğŸ“­ Contact

If your have any comments or questions, feel free to contact [borisyang326@gmail.com](mailto:borisyang326@gmail.com)

## ğŸ“ Citation

If our work helps your research or applications, please consider citing our paper:

```bibtex
@article{yang2025order,
  author = {Yang, Bo and Cao, Ying},
  title = {Order Matters: Learning Element Ordering for Graphic Design Generation},
  year = {2025},
  issue_date = {August 2025},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {44},
  number = {4},
  issn = {0730-0301},
  url = {https://doi.org/10.1145/3730858},
  doi = {10.1145/3730858},
  journal = {ACM Trans. Graph.},
  articleno = {34},
  numpages = {16}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
